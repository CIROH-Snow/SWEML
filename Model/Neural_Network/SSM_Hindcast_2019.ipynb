{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03363aa0",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "<img align = 'center' src=\"../../Images/ML_SWE.jpg\" alt = '.../Images/' width = '1000'/>\n",
    "\n",
    "## Prediction Simulation for Water Year 2019\n",
    "\n",
    "We will be testing and evaluating the performance of the model over the 2019 WY at select locations\n",
    "\n",
    "For example, the operational capacity of the model should begin at the beginning of the water year (WY week 1) with a previous SWE value of 0-in for each 1-km grid.\n",
    "Model evaluation could then assess the forecasting skill on a hold-out dataset of an entire year in which known neighboring values do not control predictions, but rather driving to-date predictions from the predicted previous SWE values. \n",
    "Due to the high model performance, future work will target the assessment of model skill with an operational motivation\n",
    "\n",
    "## Model Training/Testing influence on Model Results.\n",
    "\n",
    "The model training/testing partitioning methodology has a strong influence on model performance and the goal of model evaluation.\n",
    "The objective of the modeling effort was to examine the spatial extrapolation capacity of the model from selected monitoring stations to the overall region, best suited to a 75/25% training/testing split, respectively.\n",
    "While it is critical to address the strong serial correlation in SWE accumulation and melt throughout the season, the high correlation between weeks has the potential to inflate model skill when using a 75/25% training/testing split due to the previous SWE feature being known.\n",
    "An assessment of the operational capacity of the model is different than assessing the ability to extrapolate regional SWE from in-situ monitoring stations.\n",
    "For example, the operational capacity of the model should begin at the beginning of the water year (WY week 1) with a previous SWE value of 0-in for each 1-km grid.\n",
    "Model evaluation could then assess the forecasting skill on a hold-out dataset of an entire year in which known neighboring values do not control predictions, but rather driving to-date predictions from the predicted previous SWE values. \n",
    "Due to the high model performance, future work will target the assessment of model skill with an operational motivation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13048ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 15:54:59.895941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-19 15:54:59.895967: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, '..') #sys allows for the .ipynb file to connect to the shared folder files\n",
    "from shared_scripts import Hindcast_Initialization, NSM_SCA\n",
    "\n",
    "#Set working directories\n",
    "cwd = os.getcwd()\n",
    "datapath = f\"{os.path.expanduser('~')}/SWEML\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3972a22-7e39-4575-a738-e3bc545a2a2e",
   "metadata": {},
   "source": [
    "## Bring prediction DFs in\n",
    "The Prediction DFs do not store after a git push and this will save your results, make sure you have the correct model name in the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80aea1d-de20-4d76-a170-2740096f7813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files from AWS to local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [07:39<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# frequency = 'Daily'\n",
    "# fSCA = True\n",
    "# modelname = \"Neural_Network\"\n",
    "# Hindcast_Initialization.AWS_to_Hindcast(modelname, frequency, fSCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910ccf5-27b2-46c7-931d-5c4ecb690923",
   "metadata": {},
   "source": [
    "# Initiate Simulation\n",
    "\n",
    "You can run all regions or just ones for development, not that only the regions entered below will work for the Hindcast Evaluator\n",
    "\n",
    "## Run your SSM in hindcast mode to evaluate operational capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82649fa-4b3e-4a34-b4ac-a5504298b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, '..') #sys allows for the .ipynb file to connect to the shared folder files\n",
    "from shared_scripts import Hindcast_Initialization, NSM_SCA, SSWEET\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Set working directories\n",
    "cwd = os.getcwd()\n",
    "datapath = f\"{os.path.expanduser('~')}/SWEML\" \n",
    "\n",
    "new_year = '2019'\n",
    "threshold = '10.0' #This threshold is standardized for now, to recalculate see Dr. Johnson\n",
    "Region_list = [ 'N_Sierras', 'S_Sierras_High', 'S_Sierras_Low','Greater_Yellowstone', \n",
    "    'N_Co_Rockies', 'SW_Mont', 'SW_Co_Rockies', 'GBasin', 'N_Wasatch', 'N_Cascade',\n",
    "     'S_Wasatch', 'SW_Mtns', 'E_WA_N_Id_W_Mont', 'S_Wyoming', 'SE_Co_Rockies', \n",
    "     'Sawtooth', 'Ca_Coast', 'E_Or', 'N_Yellowstone', 'S_Cascade', 'Wa_Coast',\n",
    "     'Greater_Glacier', 'Or_Coast'\n",
    "              ]\n",
    "\n",
    "# Region_list = [ 'N_Cascade']\n",
    "\n",
    "fSCA = True\n",
    "\n",
    "frequency = 'Daily' #enter Weekly or Daily\n",
    "\n",
    "datelist = Hindcast_Initialization.Hindcast_Initialization(cwd, datapath, new_year, threshold, Region_list, frequency, fSCA = fSCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0062b00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/268 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NSM_SCA' object has no attribute 'fSCA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     10\u001b[0m Snow \u001b[38;5;241m=\u001b[39m NSM_SCA\u001b[38;5;241m.\u001b[39mNSM_SCA(day, threshold\u001b[38;5;241m=\u001b[39mthreshold, Regions \u001b[38;5;241m=\u001b[39m Region_list, modelname \u001b[38;5;241m=\u001b[39m model, frequency \u001b[38;5;241m=\u001b[39m frequency, fSCA \u001b[38;5;241m=\u001b[39m  fSCA)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#Go get SNOTEL observations - all data currently loaded, set to True to download\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Snow.Get_Monitoring_Data_Threaded(getdata = True)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#Make predictions, set NewSim to False\u001b[39;00m\n\u001b[1;32m     25\u001b[0m  \u001b[38;5;66;03m#Look to multiprocess, each region can do a prediction to speed things up. set NewSim to true for New simulation, turn to false once all data has been proces and saved.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mSnow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWE_Predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNewSim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCorrections\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfSCA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfSCA\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SWEML/Model/Neural_Network/../shared_scripts/NSM_SCA.py:257\u001b[0m, in \u001b[0;36mNSM_SCA.SWE_Predict\u001b[0;34m(self, SCA, NewSim, modelname, Corrections, fSCA)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSWE_Predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, SCA\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, NewSim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, modelname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeural_Network\u001b[39m\u001b[38;5;124m'\u001b[39m, Corrections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, fSCA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# load first SWE observation forecasting dataset with prev and delta swe for observations.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelname \u001b[38;5;241m=\u001b[39m modelname\n\u001b[0;32m--> 257\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Predictions/Hold_Out_Year/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrequency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/fSCA_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfSCA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Prediction_DF_SCA_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NewSim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m      \n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m#set up predictions for next timestep\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         fdate \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate)\u001b[38;5;241m+\u001b[39mtimedelta(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NSM_SCA' object has no attribute 'fSCA'"
     ]
    }
   ],
   "source": [
    "#run the model through all time (data acqusition already completed)\n",
    "model = 'Neural_Network'\n",
    "frequency = 'Daily'\n",
    "threshold = 10\n",
    "fSCA = True\n",
    "\n",
    "for day in tqdm(datelist):\n",
    "    #print('Updating SWE predictions for ', day)\n",
    "    #connect interactive script to Wasatch Snow module\n",
    "    Snow = NSM_SCA.NSM_SCA(day, threshold=threshold, Regions = Region_list, modelname = model, frequency = frequency, fSCA =  fSCA)\n",
    "    \n",
    "    #Go get SNOTEL observations - all data currently loaded, set to True to download\n",
    "    #Snow.Get_Monitoring_Data_Threaded(getdata = True)\n",
    "\n",
    "    #Initialize/Download the granules, all data preprocessed for the SSM activRegion_listhange to True to use the functions.\n",
    "   # Snow.initializeGranules(getdata = True)\n",
    "\n",
    "    #Process observations into Model prediction ready format,\n",
    "    #Snow.Data_Processing(SCA = True)\n",
    "\n",
    "    #Agument with SCA\n",
    "    #Snow.augmentPredictionDFs()\n",
    " \n",
    "    #Make predictions, set NewSim to False\n",
    "     #Look to multiprocess, each region can do a prediction to speed things up. set NewSim to true for New simulation, turn to false once all data has been proces and saved.\n",
    "    Snow.SWE_Predict(NewSim = False, Corrections = False, fSCA = fSCA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2290d9",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Model Hindcast complete\n",
    "\n",
    "Lets see how your model performs within SSWEET in the [Hindcast_Evaluation](./Hindcast_Evaluation.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b64a8b9-47ac-45ef-885f-98339b0983ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['submission_format.h5', '2019_predictions.h5']\n",
      "Pushing files to AWS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "modelname= 'Neural_Network'\n",
    "folderpath = 'Predictions/Hold_Out_Year/Daily/fSCA_True/'\n",
    "AWSpath = f\"Hold_Out_Year/Daily/\"\n",
    "type = '.h5'\n",
    "Hindcast_Initialization.Hindcast_to_AWS(modelname, folderpath, AWSpath, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1474bce-324e-4bd4-8fc7-c42bbbf48141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWEML_env",
   "language": "python",
   "name": "sweml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
