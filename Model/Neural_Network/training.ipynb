{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "\n",
    "<img align = 'center' src=\"../../Images/ML_SWE.jpg\" alt = '.../Images/' width = '1000'/>\n",
    "\n",
    "# Model Training\n",
    "\n",
    "\n",
    "This notebook exemplifies the Sierra Snow Model (SSM) (a derivation of the National Snow Model (NSM)) data processing (through the DataProcess.py script), and model training, predictions, and preliminary evaluation via the MLP_model.py script.\n",
    "With the focus of GeoSMART Hack Week to advance machine learning modeling skill sets, the motivation of the SSM project is for participants to modify the MLP_model.py script.\n",
    "Suggested modifications include optimizing the current multilayered-perceptron (MLP) neural network algorithm or selecting and optimizing a different ML algorithm (strongly encouraged).\n",
    "We encourage advanced modelers to contact Dr. Ryan Johnson (rjohnson18@ua.edu) for ideas and methods to optimize the model framework, there are several concepts of interest including feature engineering, domain optimization, feature selection, etc.\n",
    "\n",
    "The following workflow exemplifies the steps and python files to process the training data, train a model, produce predictions, and perform preliminary evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import MLP_Model\n",
    "import sys\n",
    "sys.path.insert(0, '..') #sys allows for the .ipynb file to connect to the shared folder files\n",
    "from shared_scripts import DataProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Model Training and Testing Schema\n",
    "\n",
    "The motivation the project is to advance the SSM skill for extrapolating regional SWE dynamics from in-situ observations.\n",
    "To develop and test the SSM, we will train the model on NASA Airborne Snow Observatory (ASO) and snow course observations spanning 2013-2018, and some of 2019.\n",
    "Within this training dataset, model training will use a random 75-25\\% train-test data split. \n",
    "The random sample function will be 1234 to ensure all participants models use the same training and testing data for this phase of model development - note, this will support an intermodel comparision.\n",
    "\n",
    "Model validation will be on water year 2019 and use the [NWM_MLP_2019_Simulation]('./NWM_MLP_2019_Simulation.ipynb').\n",
    "This historical simulation will function as a hindcast, and use the 2019 water year NASA ASO and snow course observations to determine model performance. \n",
    "\n",
    "\n",
    "Upon the completion of model training, model execution predicts 1-km resolution SWE from data up to the current date of observation provided Latitude, Longitude, corresponding topographic data, and neighboring observation input features. From the sampling of test features, Chapter [Evaluation]('./evaluation.ipynb') compares the modeled 1-km grid SWE values to the observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define hold out year\n",
    "HOY = 2019\n",
    "modelname = \"Neural_Network\"\n",
    "Region_list = [ 'N_Sierras', 'S_Sierras_High', 'S_Sierras_Low','Greater_Yellowstone', \n",
    "     'N_Co_Rockies', 'SW_Mont', 'SW_Co_Rockies', 'GBasin', 'N_Wasatch', 'N_Cascade',\n",
    "     'S_Wasatch', 'SW_Mtns', 'E_WA_N_Id_W_Mont', 'S_Wyoming', 'SE_Co_Rockies', \n",
    "     'Sawtooth', 'Ca_Coast', 'E_Or', 'N_Yellowstone', 'S_Cascade', 'Wa_Coast',\n",
    "     'Greater_Glacier', 'Or_Coast'\n",
    "              ]\n",
    "#Run data processing script to partition key regional dataframes\n",
    "#note, need to load RegionTrain_SCA.h5,\n",
    "RegionTrain, RegionTest, RegionObs_Train, RegionObs_Test, RegionTest_notScaled = DataProcess.DataProcess(HOY, modelname, Region_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Multilayered Precepton Network (MLP)\n",
    "Given the identified optimal feature sets using recursive feature elimination (RFE), this step trains your model.\n",
    "Here, the model is an ANN multilayer perceptron (MLP) regression model to estimate SWE found in the [MLP_Model]('./MLP_Model.py') file.\n",
    "This file serves as a template for Hackweek participants to modify and by following the template, participants will be able to streamline model development and evaluation.\n",
    "\n",
    "<img align = 'left' src=\"../../Images/MLP_architecture.png\" alt = 'image' width = '450'/>\n",
    "\n",
    "The MLP is a classical type of feedforward ANN, successfully and frequently applied in environmental modeling applications.\n",
    "The MLP regression model estimates a target variable by learning a non-linear function to describe the target from an input vector of features.\n",
    "It performs learning via a back-propagation algorithm over a series of hidden layers containing interconnected nodes (neurons). \n",
    "The neurons connect bordering layers by a summation of weights and an activation function transforms model outputs to predicted values (i.e., SWE (in)). \n",
    "The model calculates error and adjusts the weights to minimize the error during model training, supporting the use of \n",
    "MLPs to effectively describe a target variable with any function, continuous or discontinuous. \n",
    "\n",
    "Model training leveraged the Keras API within the TensorFlow library.\n",
    "We selected the popular, open-source TensorFlow and Keras platforms for their wide applicability and capabilities in deep learning.\n",
    "The MLP model for the region consists of an input layer containing nodes for each feature in the optimized feature space, 7 dense hidden layers, and an output layer of the target SWE value. \n",
    "Model formulation uses the Rectified Linear Unit (ReLu) activation function to transform each hidden layer to non-linearize the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model training, each participants model will be different but should follow the prescribed input feature template\n",
    "epochs= 60\n",
    "MLP_Model.Model_train(epochs, RegionTrain, RegionTest, RegionObs_Train, RegionObs_Test, Region_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Make predictions on the random sample of testing data\n",
    "<img align = 'center' src=\"../../Images/predictivemodeling.jpg\" alt = 'image' width = '600'/>\n",
    "\n",
    "The next phase of model development is to examine model performance on the random sample of testing data.\n",
    "Refining model predictions at this phase will ensure the best model performance for the Hold-Out-Year validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Need to create Predictions folder if running for the first time\n",
    "Predictions = MLP_Model.Model_predict(RegionTest, RegionObs_Test, RegionTest_notScaled, Region_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Perform Preliminary Model Evaluation\n",
    "\n",
    "How does your model performance? \n",
    "We are using simple model evaluation metrics of R2 and RMSE to guage model performance.\n",
    "You will perform a more exhaustive model evaluation in the [Evaluation]('./evaluation.ipynb') chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Performance = MLP_Model.Prelim_Eval(Predictions)\n",
    "Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Now that we have a trained model producing acceptable performance, it is time to more rigorously evaluate its performance using the [Standardized Snow Water Equivalent Tool](./SSWEET.py) within an interactive [evaluation notebook](./evaluation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model weights and key criteria to AWS S3\n",
    "modelname = 'Neural_Network'\n",
    "Region = 'N_Sierras'\n",
    "MLP_Model.save_model_AWS(modelname, Region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWEML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
