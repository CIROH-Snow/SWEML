{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tables\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import hydroeval as he\n",
    "from pickle import dump\n",
    "import pickle \n",
    "from tqdm import tqdm\n",
    "\n",
    "#A function to load model predictions\n",
    "def load_Predictions(cwd):\n",
    "    Regions = ['N_Sierras','S_Sierras_Low', 'S_Sierras_High']\n",
    "    RegionTest = {}\n",
    "    for Region in Regions:\n",
    "        RegionTest[Region] = pd.read_hdf(f\"{cwd}/Predictions/Testing/Predictions.h5\", key = Region)\n",
    "        \n",
    "    return RegionTest\n",
    "\n",
    "\n",
    "#Function to convert predictions into parity plot plus evaluation metrics\n",
    "def parityplot(RegionTest):\n",
    "    \n",
    "    #Get regions\n",
    "    Regions = list(RegionTest.keys())\n",
    "    \n",
    "    #put y_pred, y_pred_fSCA, y_test, Region into one DF for parity plot\n",
    "    Compare_DF = pd.DataFrame()\n",
    "    cols = ['Region', 'y_test', 'y_pred', 'y_pred_fSCA']\n",
    "    for Region in Regions:\n",
    "        df = RegionTest[Region][cols]\n",
    "        Compare_DF = pd.concat([Compare_DF, df])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Plot the results in a parity plot\n",
    "    sns.set(style='ticks')\n",
    "    SWEmax = max(Compare_DF['y_test'])\n",
    "\n",
    "    sns.relplot(data=Compare_DF, x='y_test', y='y_pred', hue='Region', hue_order=Regions, aspect=1.61)\n",
    "    plt.plot([0,SWEmax], [0,SWEmax], color = 'red', linestyle = '--')\n",
    "    plt.xlabel('Observed SWE')\n",
    "    plt.ylabel('Predicted SWE')\n",
    "    plt.show()\n",
    "\n",
    "    #Run model evaluate functions\n",
    "    #Regional\n",
    "    Performance = pd.DataFrame()\n",
    "    for Region in Regions:\n",
    "        y_test = RegionTest[Region]['y_test']\n",
    "        y_pred = RegionTest[Region]['y_pred']\n",
    "        y_pred_fSCA = RegionTest[Region]['y_pred_fSCA']\n",
    "        \n",
    "        r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "        rmse = sklearn.metrics.mean_squared_error(y_test, y_pred, squared = False)\n",
    "        kge, r, alpha, beta = he.evaluator(he.kge, y_pred, y_test)\n",
    "        pbias = he.evaluator(he.pbias, y_pred, y_test)\n",
    "    \n",
    "        r2_fSCA = sklearn.metrics.r2_score(y_test, y_pred_fSCA)\n",
    "        rmse_fSCA = sklearn.metrics.mean_squared_error(y_test, y_pred_fSCA, squared = False)\n",
    "        kge_fSCA, r_fSCA, alpha_fSCA, beta_fSCA = he.evaluator(he.kge, y_pred_fSCA, y_test)\n",
    "        pbias_fSCA = he.evaluator(he.pbias, y_pred_fSCA, y_test)\n",
    "        \n",
    "        error_data = np.array([Region, \n",
    "                               round(r2,2),  \n",
    "                               round(rmse,2), \n",
    "                               round(kge[0],2),\n",
    "                               round(pbias[0],2),\n",
    "                               round(r2_fSCA,2),\n",
    "                               round(rmse_fSCA,2),\n",
    "                              round(kge_fSCA[0],2),\n",
    "                              round(pbias_fSCA[0],2)])\n",
    "        \n",
    "        error = pd.DataFrame(data = error_data.reshape(-1, len(error_data)), \n",
    "                             columns = ['Region', \n",
    "                                        'R2',\n",
    "                                        'RMSE',\n",
    "                                        'KGE', \n",
    "                                        'PBias', \n",
    "                                        'R2_fSCA',\n",
    "                                        'RMSE_fSCA',\n",
    "                                        'KGE_fSCA', \n",
    "                                        'PBias_fSCA',\n",
    "                                       ])\n",
    "        Performance = Performance.append(error, ignore_index = True)\n",
    "      \n",
    "\n",
    "    #All Sierras\n",
    "    y_test = Compare_DF['y_test']\n",
    "    y_pred = Compare_DF['y_pred']\n",
    "    y_pred_fSCA = Compare_DF['y_pred_fSCA']\n",
    "    r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "    rmse = sklearn.metrics.mean_squared_error(y_test, y_pred, squared = False) \n",
    "    kge, r, alpha, beta = he.evaluator(he.kge, y_pred, y_test)\n",
    "    pbias = he.evaluator(he.pbias, y_pred, y_test)\n",
    "    \n",
    "    r2_fSCA = sklearn.metrics.r2_score(y_test, y_pred_fSCA)\n",
    "    rmse_fSCA = sklearn.metrics.mean_squared_error(y_test, y_pred_fSCA, squared = False)\n",
    "    kge_fSCA, r_fSCA, alpha_fSCA, beta_fSCA = he.evaluator(he.kge, y_pred_fSCA, y_test)\n",
    "    pbias_fSCA = he.evaluator(he.pbias, y_pred_fSCA, y_test)\n",
    "    \n",
    "    \n",
    "    error_data = np.array(['Sierras_All',\n",
    "                            round(r2,2),  \n",
    "                               round(rmse,2), \n",
    "                               round(kge[0],2),\n",
    "                               round(pbias[0],2),\n",
    "                               round(r2_fSCA,2),\n",
    "                               round(rmse_fSCA,2),\n",
    "                              round(kge_fSCA[0],2),\n",
    "                              round(pbias_fSCA[0],2)])\n",
    "\n",
    "    error = pd.DataFrame(data = error_data.reshape(-1, len(error_data)), \n",
    "                             columns = ['Region', \n",
    "                                        'R2',\n",
    "                                        'RMSE',\n",
    "                                        'KGE', \n",
    "                                        'PBias', \n",
    "                                        'R2_fSCA',\n",
    "                                        'RMSE_fSCA',\n",
    "                                        'KGE_fSCA', \n",
    "                                        'PBias_fSCA'\n",
    "                                       ])\n",
    "    Performance = Performance.append(error, ignore_index = True)\n",
    "    display(Performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NSM_env",
   "language": "python",
   "name": "nsm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
