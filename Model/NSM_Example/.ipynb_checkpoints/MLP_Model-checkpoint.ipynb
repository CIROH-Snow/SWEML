{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c140d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplify function to just train, set up as .py file\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tables\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle \n",
    "import sklearn\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "import threading  # this is the threading library\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def atof(text):\n",
    "    try:\n",
    "        retval = float(text)\n",
    "    except ValueError:\n",
    "        retval = text\n",
    "    return retval\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    float regex comes from https://stackoverflow.com/a/12643073/190597\n",
    "    '''\n",
    "    return [ atof(c) for c in re.split(r'[+-]?([0-9]+(?:[.][0-9]*)?|[.][0-9]+)', text) ]\n",
    "\n",
    "\n",
    "def Model_train(cwd, epochs, RegionTrain, RegionTest, RegionObs_Train, RegionObs_Test):\n",
    "    \n",
    "    #Get regions\n",
    "    Regions = list(RegionTrain.keys())\n",
    "    \n",
    "    for Region in Regions:\n",
    "        print('Training model for: ', Region)\n",
    "        #set up train/test dfs\n",
    "        X_train = RegionTrain[Region].copy()\n",
    "        X_test = RegionTest[Region].copy()\n",
    "        y_train = RegionObs_Train[Region].copy()\n",
    "        y_test = RegionObs_Test[Region].copy()\n",
    "\n",
    "        #remove Date, VIIRS_SCA, and hasSnow from training and testing df\n",
    "        colrem = ['Date', 'VIIRS_SCA', 'hasSnow']\n",
    "        X_train.drop(columns = colrem, axis =1, inplace = True)\n",
    "        X_test.drop(columns = colrem, axis =1, inplace = True)\n",
    "\n",
    "        #set up prediction dataframe\n",
    "        pred_obs = pd.DataFrame(y_test)\n",
    "        pred_obs = pred_obs.rename(columns = {'SWE':'y_test'})\n",
    "\n",
    "\n",
    "        #set up model checkpoint to be able to extract best models\n",
    "        checkpointfilename ='ASWE_{val_loss:.8f}.h5'\n",
    "        checkpoint_filepath = f\"{cwd}/Model/{Region}/\"\n",
    "\n",
    "        checkpoint_filename = checkpoint_filepath+checkpointfilename\n",
    "        callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filename,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "        #get the training data shape to form MLP model input layer\n",
    "        shape = X_train.shape\n",
    "\n",
    "        #set up layer-nodes for MLP model\n",
    "        LD1=128\n",
    "        #seems like only slight increase in runtime with another layer\n",
    "        LD2=128\n",
    "        #seems like only slight increase in runtime with another layer\n",
    "        LD3=64\n",
    "        #seems like only slight increase in runtime with another layer, sig per improvement \n",
    "        LD4=64\n",
    "        LD5=32\n",
    "        LD6=16\n",
    "        LD7=5\n",
    "\n",
    "        input_1 = layers.Input(shape=(shape[1],))\n",
    "        x = layers.Dense(LD1, activation=\"relu\")(input_1)\n",
    "        x = layers.Dense(LD2, activation=\"relu\")(x)\n",
    "        x = layers.Dense(LD3, activation=\"relu\")(x)\n",
    "        x = layers.Dense(LD4, activation=\"relu\")(x)\n",
    "        x = layers.Dense(LD5, activation=\"relu\")(x)\n",
    "        x = layers.Dense(LD6, activation=\"relu\")(x)\n",
    "        x = layers.Dense(1)(x)\n",
    "\n",
    "        model = keras.Model(inputs=input_1,outputs=x)\n",
    "        model.compile(loss='mse', optimizer=keras.optimizers.Adam(1e-4), metrics=['mse'])\n",
    "        print(model.summary())\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=100,\n",
    "                            validation_data=(X_test,y_test),shuffle=True,callbacks=[callback], verbose=0)\n",
    "\n",
    "def Model_predict(cwd,  RegionTest, RegionObs_Test, RegionTest_notScaled):\n",
    "    \n",
    "    Predictions = {}\n",
    "    \n",
    "    #Get regions\n",
    "    Regions = list(RegionTest.keys())\n",
    "    \n",
    "    for Region in Regions:\n",
    "    \n",
    "     #set up test dfs\n",
    "        X_test = RegionTest[Region].copy()\n",
    "        X_test_notscaled = RegionTest_notScaled[Region]\n",
    "        y_test = RegionObs_Test[Region].copy()\n",
    "        \n",
    "     #Set up model to predict 0\" SWE if hasSnow = False\n",
    "        VIIRScols = ['Date', 'VIIRS_SCA' , 'hasSnow']\n",
    "        y_pred_VIIRS = X_test[VIIRScols].copy(deep = True)\n",
    "        y_pred_VIIRS['y_pred_fSCA'] = np.nan\n",
    "\n",
    "        for i in np.arange(0, len(y_pred_VIIRS),1):\n",
    "            if y_pred_VIIRS['hasSnow'][i] == False:\n",
    "                y_pred_VIIRS['y_pred_fSCA'][i] = 0  \n",
    "\n",
    "        #drop VIIRS cols from prediction DF\n",
    "        X_test = X_test.drop(VIIRScols, axis = 1)\n",
    "\n",
    "        pred_obs = pd.DataFrame(RegionObs_Test[Region])\n",
    "        pred_obs = pred_obs.rename(columns = {'SWE':'y_test'})\n",
    "\n",
    "        #set up model checkpoint to be able to extract best models\n",
    "        checkpoint_filepath = f\"{cwd}/Model/{Region}/\"\n",
    "\n",
    "        #load the model with highest performance\n",
    "        bestmodel = [f for f in listdir(checkpoint_filepath) if isfile(join(checkpoint_filepath, f))]\n",
    "        bestmodel.sort(key=natural_keys)\n",
    "        bestmodel = checkpoint_filepath+bestmodel[0]\n",
    "        model=load_model(bestmodel)\n",
    "        print(bestmodel)\n",
    "\n",
    "\n",
    "         #Load SWEmax\n",
    "        SWEmax = np.load(f\"{checkpoint_filepath}/{Region}_SWEmax.npy\")\n",
    "        #make predictions and rescale, the 10 is bc changed -9999 values to -10\n",
    "        y_pred = (SWEmax* model.predict(X_test))\n",
    "\n",
    "        #negative SWE is impossible, change negative values to 0\n",
    "        y_pred[y_pred < 0 ] = 0\n",
    "        y_test = (SWEmax * y_test)\n",
    "        pred_obs['y_test'] = y_test\n",
    "        pred_obs['y_pred'] = y_pred \n",
    "        pred_obs['Region'] = Region\n",
    "        \n",
    "          #Add in predictions from fSCA   \n",
    "        pred_obs = pd.concat([pred_obs, y_pred_VIIRS], axis=1)\n",
    "        pred_obs.y_pred_fSCA.fillna(pred_obs.y_pred, inplace=True)\n",
    "\n",
    "        #combine predictions with model inputs\n",
    "        df = pd.concat([pred_obs, X_test_notscaled], axis = 1)\n",
    "        df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "\n",
    "        Predictions[Region] = df\n",
    "\n",
    "        \n",
    "    return Predictions\n",
    "\n",
    "\n",
    "def Prelim_Eval(Predictions):\n",
    "    #Get regions\n",
    "    Regions = list(Predictions.keys())\n",
    "    Performance = pd.DataFrame()\n",
    "    \n",
    "    for Region in Regions:\n",
    "        print('Preliminary Model Analysis for: ', Region)\n",
    "        pred_obs = Predictions[Region]\n",
    "        \n",
    "        #set up model checkpoint to be able to extract best models\n",
    "        checkpoint_filepath = f\"{cwd}/Model/{Region}/\"\n",
    "        SWEmax = np.load(f\"{checkpoint_filepath}/{Region}_SWEmax.npy\")\n",
    "    #Run model evaluate function\n",
    "        #print(model.evaluate(X_test, y_test))\n",
    "        #Run model evaluate function\n",
    "        r2_test = sklearn.metrics.r2_score(pred_obs['y_test'], pred_obs['y_pred'])\n",
    "        rmse_test = sklearn.metrics.mean_squared_error(pred_obs['y_test'], pred_obs['y_pred'], squared = False)\n",
    "        r2_fSCA = sklearn.metrics.r2_score(pred_obs['y_test'], pred_obs['y_pred_fSCA'])\n",
    "        rmse_fSCA = sklearn.metrics.mean_squared_error(pred_obs['y_test'], pred_obs['y_pred_fSCA'], squared = False)\n",
    "\n",
    "\n",
    "        print(' R2 is ', r2_test)\n",
    "        print(' RMSE is ', rmse_test)\n",
    "        print(' R2 fSCA is ', r2_fSCA)\n",
    "        print(' RMSE fSCA is ', rmse_fSCA)\n",
    "\n",
    "        #print(\"MSE: %.4f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        error_data = np.array([Region, round(r2_test,2),  \n",
    "                               round(rmse_test,2), \n",
    "                               round(r2_fSCA,2),\n",
    "                               round(rmse_fSCA,2)])\n",
    "\n",
    "        error = pd.DataFrame(data = error_data.reshape(-1, len(error_data)), \n",
    "                             columns = ['Region', 'R2', 'RMSE', 'R2_fSCA', 'RMSE_fSCA'])\n",
    "        Performance = Performance.append(error, ignore_index = True)\n",
    "\n",
    "        #plot graph\n",
    "        plt.scatter( pred_obs['y_test'],pred_obs['y_pred'], s=5, color=\"blue\", label=\"Predictions\")\n",
    "        plt.scatter( pred_obs['y_test'],pred_obs['y_pred_fSCA'], s=5, color=\"red\", label=\"Predictions_wfFSCA\")\n",
    "        plt.plot([0,SWEmax], [0,SWEmax], color = 'red', linestyle = '--')\n",
    "        plt.xlabel('Observed SWE')\n",
    "        plt.ylabel('Predicted SWE')\n",
    "\n",
    "        #plt.plot(x_ax, y_pred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "        plt.title(Region)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    return Performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NSM_env",
   "language": "python",
   "name": "nsm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
