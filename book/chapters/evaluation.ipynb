{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Performance Evaluation \n",
    "\n",
    "\n",
    "\n",
    "### Evaluation Methodology\n",
    "Model execution produces a 1-km grid SWE estimates across the study region, where the evaluation methodology compares the modeled SWE from the testing dataset to the NASA ASO observations.\n",
    "<img align = 'right' src=\"./Images/RMSE_R2.JPG\" alt = 'image' width = '200'/>\n",
    "As a submission to the USBR Snowcast Showdown, we use standard evaluation criteria of root-mean-squared-error (RMSE) and coefficient of determination (R<sup>2</sup>) of the predictions to determine model accuracy and efficiency across the domain, as these metrics framed the evaluation criteria for the modeling competition. \n",
    "where $\\hat{y_i}$ denotes the predicted value for a sample $i$, $y_i$ the observed value, $\\bar{y}$ the average observed value, and n the total number of samples. \n",
    "\n",
    "The coefficient of determination (R<sup>2</sup>) is a unitless measurement of the proportion of explained variance of the target variable by the model.\n",
    "A maximum R<sup>2</sup> score of 1.0 indicates the predictor variables explain 100 percent of the variation in the target. \n",
    "In general, greater R<sup>2</sup> and lower RMSE represent better model predictive performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Evaluation of the Model\n",
    "Regional model evaluation is on the 25% testing data, where the known previous SWE values from NASA ASO flights support the previous SWE feature during model inference.\n",
    "The model demonstrates high spatial extrapolation of point observations (selected SNOTEL) to regional 1-km grid prediction skill across all regions with R<sup>2</sup> values approaching 0.85, low regional RMSE values (4.4-in).\n",
    "\n",
    "### Model Training/Testing influences and Bias on Model Performance.\n",
    "\n",
    "The model training/testing partitioning methodology has a strong influence on model performance and the goal of model evaluation.\n",
    "The objective of the modeling effort was to examine the spatial extrapolation capacity of the model from selected monitoring stations to the overall region, best suited to a 75/25% training/testing split, respectively.\n",
    "While it is critical to address the strong serial correlation in SWE accumulation and melt throughout the season, the high correlation between weeks has the potential to inflate model skill when using a 75/25% training/testing split due to the previous SWE feature being known.\n",
    "An assessment of the operational capacity of the model is different than assessing the ability to extrapolate regional SWE from in-situ monitoring stations.\n",
    "For example, the operational capacity of the model should begin at the beginning of the water year (WY week 1) with a previous SWE value of 0-in for each 1-km grid.\n",
    "Model evaluation could then assess the forecasting skill on a hold-out dataset of an entire year in which known neighboring values do not control predictions, but rather driving to-date predictions from the predicted previous SWE values. \n",
    "Due to the high model performance, future work will target the assessment of model skill with an operational motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tables\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pickle import dump\n",
    "import pickle \n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define new regions\n",
    "Region_list = [\n",
    "               'N_Co_Rockies',\n",
    "              ]\n",
    "\n",
    "#Load the predictions/observations for the testing dataframe\n",
    "### Load H5 train files into dictionary\n",
    "RegionTrain= {}\n",
    "for region in Region_list:\n",
    "    RegionTrain[region] = pd.read_hdf('Provided_Data/Final_Training_DF.h5', region)\n",
    "\n",
    "pred_obs = {}\n",
    "pred_obs['N_Co_Rockies'] = pd.read_hdf('Model/Model_Training/Model_Validation/Region_Predictions.h5', key = 'N_Co_Rockies')\n",
    "\n",
    "y_pred = pred_obs['N_Co_Rockies']['y_pred']\n",
    "y_test = pred_obs['N_Co_Rockies']['y_test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the results in a parity plot\n",
    "sns.set(style='ticks')\n",
    "SWEmax = max(y_test)\n",
    "\n",
    "sns.relplot(data=pred_obs['N_Co_Rockies'], x='y_test', y='y_pred', hue='Region', hue_order=Region_list, aspect=1.61)\n",
    "plt.plot([0,SWEmax], [0,SWEmax], color = 'red', linestyle = '--')\n",
    "plt.xlabel('Observed SWE')\n",
    "plt.ylabel('Predicted SWE')\n",
    "plt.show()\n",
    "\n",
    "#Run model evaluate functions\n",
    "r2_test = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "rmse_test = sklearn.metrics.mean_squared_error(y_test, y_pred, squared = False)\n",
    "print(' R2 is ', r2_test)\n",
    "print(' RMSE is ', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance is quite high.\n",
    "\n",
    "## More in-depth model evaluation.\n",
    "We want to evaluate the model over the course of seasonal snow accumulation and melt, at differnt elevation bands, and spatially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eval_DF(RegionTrain, Region, Predictions):\n",
    "    #get the testing split\n",
    "    y = RegionTrain[Region]['SWE']\n",
    "    X = RegionTrain[Region]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234)\n",
    "    \n",
    "    #Combine predictions with testing testing dependent DF,     \n",
    "    X_test['y_pred'] = Predictions[Region]['y_pred']\n",
    "    X_test['error'] = X_test['SWE'] - X_test['y_pred']\n",
    "    \n",
    "    #select key topographical and temporal features of interest for model evaluation\n",
    "    cols = ['Date', 'Long', 'Lat', 'elevation_m', 'prev_SWE', 'WYWeek', 'northness', 'SWE','y_pred', 'error']\n",
    "    X_test = X_test[cols]\n",
    "    \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the data into a useful dataframe for analysis\n",
    "x = Eval_DF(RegionTrain, 'N_Co_Rockies', pred_obs)\n",
    "\n",
    "\n",
    "#Plot the temporal error\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x, x='WYWeek', y='error', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Water year Week')\n",
    "plt.ylabel('SWE Error (in)')\n",
    "plt.title(\"Error over time\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A substantial amount of model error can  be attributed to time.\n",
    "It appears the model exihibits limitations in predicting SWE during the melt phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the error by elevation\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x, x='elevation_m', y='error', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Elevation')\n",
    "plt.ylabel('SWE Error (in)')\n",
    "plt.title(\"Error by Elevation\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model error increases with elevation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the error by slope/angle = northness\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x, x='northness', y='error', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Northness')\n",
    "plt.ylabel('SWE Error (in)')\n",
    "plt.title(\"Error by Northness\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There appears to be no significant model error attributed to northness\n",
    "\n",
    "Lets look at the model predictions spatially, any patterns we can observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load regionalized geospatial data\n",
    "RegionTrain = open(\"Provided_Data/RegionTrain.pkl\", \"rb\")\n",
    "RegionSnotel = open(\"Provided_Data/RegionSnotel.pkl\", \"rb\")\n",
    "\n",
    "RegionTrain = pd.read_pickle(RegionTrain)\n",
    "RegionSnotel = pd.read_pickle(RegionSnotel)\n",
    "\n",
    "#Create Geospatial prediction point DF\n",
    "Pred_Geo = RegionTrain['N_Co_Rockies'].copy()\n",
    "Pred_Geo = Pred_Geo.reset_index().drop_duplicates(subset='cell_id', keep='last').set_index('cell_id').sort_index()\n",
    "cols = ['Long','Lat','elevation_m','slope_deg','aspect']\n",
    "Pred_Geo= Pred_Geo[cols].reset_index()\n",
    "Pred_Geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Folium and Geopandas to spatially visualize the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import features\n",
    "from folium.plugins import StripePattern\n",
    "import branca.colormap as cm\n",
    "import vincent\n",
    "from vincent import AxisProperties, PropertySet, ValueRef, Axis\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts, streams\n",
    "from bokeh.models import HoverTool\n",
    "import hydroeval as he\n",
    "import json\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "#Map locations and scoring of sites\n",
    "#def Map_Plot_Eval(self, freq, df, size):\n",
    "def Map_Plot_Eval(GeoDF, Snotel, obs, err, pred, yaxis, error_metric):   \n",
    "\n",
    "    print('Plotting monitoring station locations')\n",
    "    cols =  ['cell_id', 'Lat', 'Long', 'geometry']\n",
    "\n",
    "    df_map = GeoDF[cols].copy()\n",
    "\n",
    "    #Get Centroid of watershed\n",
    "    centeroid = df_map.dissolve().centroid\n",
    "\n",
    "    # Create a Map instance\n",
    "    m = folium.Map(location=[centeroid.y[0], centeroid.x[0]], tiles = 'Stamen Terrain', zoom_start=8, \n",
    "                   control_scale=True)\n",
    "    #add legend to map\n",
    "    if error_metric == 'KGE':\n",
    "        colormap = cm.StepColormap(colors = ['darkred', 'r', 'orange', 'g'], vmin = 0, vmax = 1, index = [0,0.4,0.6,0.85,1])\n",
    "        colormap.caption = 'Model Performance (KGE)'\n",
    "        \n",
    "    elif error_metric == 'in':\n",
    "        colormap = cm.StepColormap(colors = ['g', 'orange', 'r', 'darkred'], vmin = 0, vmax = 20, index = [0,2,6,10,20])\n",
    "        colormap.caption = 'Model Error (in)'\n",
    "        \n",
    "    elif error_metric == '%':\n",
    "        colormap = cm.StepColormap(colors = ['g', 'orange', 'r', 'darkred'], vmin = 0, vmax = 50, index = [0,10,20,30,50])\n",
    "        colormap.caption = 'Model Error (%)'\n",
    "        \n",
    "    \n",
    "    m.add_child(colormap)\n",
    "\n",
    "    ax = AxisProperties(\n",
    "    labels=PropertySet(\n",
    "        angle=ValueRef(value=300),\n",
    "        align=ValueRef(value='right')\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in obs.columns:\n",
    "\n",
    "\n",
    "        #get site information\n",
    "        site = i\n",
    "        Obs_site = 'Observations'#_' + site\n",
    "        Pred_site = 'Predictions'#_' + site\n",
    "        Err_site = 'Errors'#_' + site\n",
    "\n",
    "\n",
    "        #get modeled, observed, and error information for each site\n",
    "        df = pd.DataFrame(obs[site])\n",
    "        df = df.rename(columns = {site: Obs_site})\n",
    "        df[Pred_site] = pd.DataFrame(pred[site])\n",
    "        df[Err_site] = pd.DataFrame(err[site])\n",
    "        \n",
    "        #drop na values\n",
    "        df.dropna(inplace = True)\n",
    "\n",
    "        if error_metric == 'KGE':\n",
    "            #set the color of marker by model performance\n",
    "            kge, r, alpha, beta = he.evaluator(he.kge, df[Pred_site].astype('float32'), df[Obs_site].astype('float32'))\n",
    "\n",
    "            if kge[0] > 0.85:\n",
    "                color = 'green'\n",
    "\n",
    "            elif kge[0] > 0.6:\n",
    "                color = 'orange'\n",
    "\n",
    "            elif kge[0] > 0.40:\n",
    "                color = 'red'\n",
    "\n",
    "            else:\n",
    "                color = 'darkred'\n",
    "                \n",
    "        #error in absolute value and inches       \n",
    "        elif error_metric == 'in':\n",
    "            error = np.abs(np.mean(df[Obs_site] - df[Pred_site]))\n",
    "            if error < 2:\n",
    "                color = 'green'\n",
    "\n",
    "            elif error < 6:\n",
    "                color = 'orange'\n",
    "\n",
    "            elif error <10:\n",
    "                color = 'red'\n",
    "\n",
    "            else:\n",
    "                color = 'darkred'\n",
    "        \n",
    "        #mean percentage error\n",
    "        elif error_metric == '%':\n",
    "            #make all predictions and observations below 1\", 1\" to remove prediction biases, it does not matter if there\n",
    "            #is 0.5\" or 0.9\" of SWE but the percentage error here will be huge and overpowering\n",
    "            df[df[Obs_site]<1] = 1\n",
    "            df[df[Pred_site]<1] = 1\n",
    "            \n",
    "            error = np.mean(np.abs(df[Obs_site] - df[Pred_site])/df[Obs_site])*100\n",
    "            if error < 10:\n",
    "                color = 'green'\n",
    "\n",
    "            elif error < 20:\n",
    "                color = 'orange'\n",
    "\n",
    "            elif error <30:\n",
    "                color = 'red'\n",
    "\n",
    "            else:\n",
    "                color = 'darkred'\n",
    "                \n",
    "\n",
    "        title_size = 14\n",
    "\n",
    "        #create graph and convert to json\n",
    "        graph = vincent.Scatter(df, height=300, width=500)\n",
    "        graph.axis_titles(x='Datetime', y=yaxis)\n",
    "        graph.legend(title= 'Legend')\n",
    "        graph.colors(brew='Paired')\n",
    "        graph.x_axis_properties(title_size=title_size, title_offset=35,\n",
    "                      label_angle=300, label_align='right', color=None)\n",
    "        graph.y_axis_properties(title_size=title_size, title_offset=-30,\n",
    "                      label_angle=None, label_align='right', color=None)\n",
    "\n",
    "        data = json.loads(graph.to_json())\n",
    "\n",
    "        #Add marker with point to map, https://fontawesome.com/v4/cheatsheet  - needs to be v4.6 or less\n",
    "        lat_long = df_map[df_map['cell_id'] == i]\n",
    "        lat = lat_long['Lat'].values[0]\n",
    "        long = lat_long['Long'].values[0]\n",
    "\n",
    "        mk = features.Marker([lat, long], icon=folium.Icon(color=color, icon = ' fa-ge', prefix = 'fa'))\n",
    "        p = folium.Popup()\n",
    "        v = features.Vega(data, width=\"100%\", height=\"100%\")\n",
    "\n",
    "        mk.add_child(p)\n",
    "        p.add_child(v)\n",
    "        m.add_child(mk)\n",
    "        \n",
    "        \n",
    "    # add SNOTEL marker one by one on the map\n",
    "    for i in range(0,len(Snotel)):\n",
    "        \n",
    "\n",
    "        folium.Marker(\n",
    "          location=[Snotel.iloc[i]['Lat'], Snotel.iloc[i]['Long']],\n",
    "            icon=folium.Icon(color='blue', icon = 'fa-area-chart', prefix = 'fa'),\n",
    "            tooltip = str(Snotel.iloc[i]['location']) + \": \" + str(Snotel.iloc[i]['station_id']),\n",
    "          popup= str(Snotel.iloc[i]['location']) + \": \" + str(Snotel.iloc[i]['elevation_m']) + \"m\",\n",
    "       ).add_to(m)\n",
    "\n",
    "    display(m)\n",
    "    \n",
    "    \n",
    "def df_transpose(df, obs):\n",
    "    #get index\n",
    "    date_idx = df.index.unique()\n",
    "    #get columns names, aka sites\n",
    "    sites = df['cell_id'].values\n",
    "    #make dataframe\n",
    "    DF =pd.DataFrame(index = date_idx)\n",
    "    for site in tqdm(sites):\n",
    "        s = pd.DataFrame(df[df['cell_id'] == site][obs])\n",
    "        DF = DF.join(s)\n",
    "        DF = DF.rename(columns ={obs: site})\n",
    "    DF = DF.loc[:,~DF.columns.duplicated()].copy()\n",
    "    return DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to put the predictions, obs, error in s time series format\n",
    "x.index = x.index.set_names(['cell_id'])\n",
    "\n",
    "#predictions\n",
    "x_pred = x.copy()\n",
    "cols = ['Date','y_pred']\n",
    "x_pred = x_pred[cols].reset_index().set_index('Date').sort_index()\n",
    "x_pred = df_transpose(x_pred, 'y_pred')\n",
    "\n",
    "#observations\n",
    "x_obs = x.copy()\n",
    "cols = ['Date','SWE']\n",
    "x_obs = x_obs[cols].reset_index().set_index('Date').sort_index()\n",
    "x_obs = df_transpose(x_obs, 'SWE')\n",
    "\n",
    "#error\n",
    "x_err = x.copy()\n",
    "cols = ['Date','error']\n",
    "x_err = x_err[cols].reset_index().set_index('Date').sort_index()\n",
    "x_err = df_transpose(x_err, 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get SNOTEL sites used as features\n",
    "#load RFE optimized features\n",
    "Region_optfeatures= pickle.load(open(\"Model/Model_Features/Optimal_Features.pkl\", \"rb\"))\n",
    "Sites = [match for match in Region_optfeatures['N_Co_Rockies'] if 'Delta_SWE'  in match]\n",
    "for i in np.arange(0, len(Sites),1):\n",
    "    Sites[i] = Sites[i].replace('Delta_SWE_', '')   \n",
    "\n",
    "\n",
    "    \n",
    "#Convert the Prediction Geospatial dataframe into a geopandas dataframe\n",
    "GeoDF = gpd.GeoDataFrame(Pred_Geo, geometry = gpd.points_from_xy(Pred_Geo.Long, Pred_Geo.Lat))\n",
    "SNOTEL_Geo = gpd.GeoDataFrame(RegionSnotel['N_Co_Rockies'], geometry = gpd.points_from_xy(RegionSnotel['N_Co_Rockies'].Long, RegionSnotel['N_Co_Rockies'].Lat))\n",
    "\n",
    "#Select sites used for prediction\n",
    "SNOTEL_Geo = SNOTEL_Geo.set_index('station_id').T[Sites].T.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folium Interactive Spatial Plotting\n",
    "Run folium plotting function.\n",
    "Note the last metric ('Error') can be set to 'KGE', 'in', or '%.\n",
    "The physical error (in) illustrates how close the predictions are to the observed, the mean percentage error (%) illustrates the perentagewise prediction accuracy, and KGE (KGE) illustrates the mean, variance and correlation on model performance, however, it is only useful for sites with multiple predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folium plot\n",
    "Map_Plot_Eval(GeoDF,SNOTEL_Geo, x_obs, x_err, x_pred, 'SWE (in)', '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially evaluating the Model via KGE\n",
    "The model demonstrates a lot of error using KGE. \n",
    "Note, the blue icons are the SNOTEL sites used to inform predictions.\n",
    "We include the SNOTEL locations to investigate potential errors stemming from the proximity of the prediction locations and the in situ observations.\n",
    "<img align = 'center' src=\"./Images/Spatial_Analysis_KGE.JPG\" alt = 'image' width = '1000'/>\n",
    "Further analysis of when clicking on the icons with poor performance indicates this is likley because of a lack of predictions. \n",
    "The sites with one or two predictions diplay the least KGE.\n",
    "<img align = 'center' src=\"./Images/Spatial_Analysis_KGE_icon.JPG\" alt = 'image' width = '1000'/>\n",
    "\n",
    "### Spatially evaluating the Model via error in inches\n",
    "The model predicts values close to the target and we see that looking at the physical error in inches provides much better insight into model performance. \n",
    "This demonstrates that model evaluation should use more than one metric.\n",
    "<img align = 'center' src=\"./Images/Spatial_Analysis_in.JPG\" alt = 'image' width = '1000'/>\n",
    "\n",
    "\n",
    "### Spatially evaluating the Model via error in percentage from the observed\n",
    "<img align = 'center' src=\"./Images/Spatial_Analysis_Perc.JPG\" alt = 'image' width = '1000'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a lot of spatial errors, lets see if we can figure out why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the error by the previous weeks SWE\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x, x='prev_SWE', y='error', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Previous Weeks SWE')\n",
    "plt.ylabel('SWE Error (in)')\n",
    "plt.title(\"Error by Previous week's SWE\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The primary cause of model error is not having a Previous SWE value!\n",
    "Wow, this plot clearly identifies where the model errors can be attributed to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More In-Depth Model Evaluation\n",
    "### Missing Previous week's values have a substantial impact on model performance.\n",
    "Lets look at the predictions that have a previous week's value and evaluate how the model performs.\n",
    "\n",
    "The model evaluation indicate a strong correlation between observed and predicted SWE, with few outliers existing in the model prediction.\n",
    "Selecting predictions that have a previous week's value result in substantially greater R<sup>2</sup> values approaching 1 (0.99) for the Upper Colorado River Basin region, indicating the predictor terms capture nearly all of the variance in SWE.\n",
    "Complementing the high R<sup>2</sup> values, the RMSE drops over 3\" to 0.86\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select for locations where there is a previous week's observation\n",
    "x_prev = x[x['prev_SWE']>=0]\n",
    "\n",
    "SWEmax = max(x_prev['SWE'])\n",
    "\n",
    "sns.relplot(data=x_prev, x='SWE', y='y_pred', hue_order=Region_list, aspect=1.61)\n",
    "plt.plot([0,SWEmax], [0,SWEmax], color = 'red', linestyle = '--')\n",
    "plt.xlabel('Observed SWE')\n",
    "plt.ylabel('Predicted SWE')\n",
    "plt.show()\n",
    "\n",
    "#Run model evaluate functions\n",
    "r2_test = sklearn.metrics.r2_score(x_prev['SWE'], x_prev['y_pred'])\n",
    "rmse_test = sklearn.metrics.mean_squared_error(x_prev['SWE'], x_prev['y_pred'], squared = False)\n",
    "print(' R2 is ', r2_test)\n",
    "print(' RMSE is ', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greatly improved modeling performorance!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the error by elevation\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x_prev, x='elevation_m', y='error', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Elevation')\n",
    "plt.ylabel('SWE Error (in)')\n",
    "plt.title(\"Error by Elevation\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a small bias in error, increasing at higher elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the error by slope/angle = northness\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x_prev, x='northness', y='error', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Northness')\n",
    "plt.ylabel('SWE Error (in)')\n",
    "plt.title(\"Error by Northness\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is no apparent bias by northness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the temporal error\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x_prev, x='WYWeek', y='error', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Water year Week')\n",
    "plt.ylabel('SWE Error (in)')\n",
    "plt.title(\"Error over time\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The majority of model error can clearly be attributed to time.\n",
    "It appears the model exihibits limitations in predicting SWE during the melt phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the error by slope/angle = northness\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x_prev, x='prev_SWE', y='error', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Previous weeks SWE (in)')\n",
    "plt.ylabel('SWE Error (in)')\n",
    "plt.title(\"Error by Northness\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at the errors spatially again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to put the predictions, obs, error in s time series format\n",
    "x_prev.index = x_prev.index.set_names(['cell_id'])\n",
    "\n",
    "#predictions\n",
    "x_pred = x_prev.copy()\n",
    "cols = ['Date','y_pred']\n",
    "x_pred = x_pred[cols].reset_index().set_index('Date').sort_index()\n",
    "x_pred = df_transpose(x_pred, 'y_pred')\n",
    "\n",
    "#observations\n",
    "x_obs = x_prev.copy()\n",
    "cols = ['Date','SWE']\n",
    "x_obs = x_obs[cols].reset_index().set_index('Date').sort_index()\n",
    "x_obs = df_transpose(x_obs, 'SWE')\n",
    "\n",
    "#error\n",
    "x_err = x_prev.copy()\n",
    "cols = ['Date','error']\n",
    "x_err = x_err[cols].reset_index().set_index('Date').sort_index()\n",
    "x_err = df_transpose(x_err, 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run folium plotting function\n",
    "Map_Plot_Eval(GeoDF,SNOTEL_Geo, x_obs, x_err, x_pred, 'SWE (in)', 'in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially evaluating the Model via KGE\n",
    "Selecting the prediction where there was a previous SWE valuel demonstrates significanly increased KGE. \n",
    "Note, the blue icons are the SNOTEL sites used to inform predictions and are more visible now.\n",
    "When running interactively, clicking on the SNOTEL icon shows the SNOTEL site information.\n",
    "We include the SNOTEL locations to investigate potential errors stemming from the proximity of the prediction locations and the in situ observations.\n",
    "<img align = 'center' src=\"./Images/Spatial_Analysis_KGE_Prev.JPG\" alt = 'image' width = '1000'/>\n",
    "\n",
    "\n",
    "### Spatially evaluating the Model via error in inches\n",
    "The model predicts values close to the target and we see that looking at the physical error in inches complements the increased model performance of the KGE metric. \n",
    "Still, the use of more than one metric supports a more comprehensive evaluation of model performance.\n",
    "<img align = 'center' src=\"./Images/Spatial_Analysis_in_Prev.JPG\" alt = 'image' width = '1000'/>\n",
    "\n",
    "Looking into the time series plot, we see the prediction closely matching the observations, resulting in low error.\n",
    "<img align = 'center' src=\"./Images/Spatial_Analysis_in_Prev_icon.JPG\" alt = 'image' width = '1000'/>\n",
    "\n",
    "### Spatially evaluating the Model via error in percentage from the observed\n",
    "<img align = 'center' src=\"./Images/Spatial_Analysis_Perc_Prev.JPG\" alt = 'image' width = '1000'/>\n",
    "\n",
    "\n",
    "Much better performance\n",
    "We can now see that the model can spatially extrapolate and that there is a significant need for improved temporal resolution data. Future work can investigate different data processing methods to realize more previous SWE features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Model Training/Testing influence on Model Results.\n",
    "\n",
    "The model training/testing partitioning methodology has a strong influence on model performance and the goal of model evaluation.\n",
    "The objective of the modeling effort was to examine the spatial extrapolation capacity of the model from selected monitoring stations to the overall region, best suited to a 75/25% training/testing split, respectively.\n",
    "While it is critical to address the strong serial correlation in SWE accumulation and melt throughout the season, the high correlation between weeks has the potential to inflate model skill when using a 75/25% training/testing split due to the previous SWE feature being known.\n",
    "An assessment of the operational capacity of the model is different than assessing the ability to extrapolate regional SWE from in-situ monitoring stations.\n",
    "For example, the operational capacity of the model should begin at the beginning of the water year (WY week 1) with a previous SWE value of 0-in for each 1-km grid.\n",
    "Model evaluation could then assess the forecasting skill on a hold-out dataset of an entire year in which known neighboring values do not control predictions, but rather driving to-date predictions from the predicted previous SWE values. \n",
    "Due to the high model performance, future work will target the assessment of model skill with an operational motivation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Prediction results\n",
    "\n",
    "Effective modeling of elevation gradients leads to a realistic modeled SWE across heterogeneous terrain. \n",
    "For example, the  higher elevation bands display greater modeled SWE values compared to lower elevations associated, and the highest elevation bands display less SWE reflecting exposed terrain subject to wind transport and snow redistribution.\n",
    "This is indicative that the model is robust to differing generalized topographical and geographical characteristics and is capable of capturing elevation gradients effectively.\n",
    "While the model uses northness as a feature to represent the average slope and aspect of the 1-km grid, overlaying the predictions on complex topography indicates a need for high resolution prediction.\n",
    "Examination of the 1-km resolution indicates it is too coarse to capture rapid topographical changes common to montane environments, but does indicate an increas in northness lead to an increase in SWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the SWE by elevation\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x_prev, x='elevation_m', y='y_pred', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Elevation')\n",
    "plt.ylabel('Predicted SWE (in)')\n",
    "plt.title(\"Predicted SWE by Elevation\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the SWE by northness\n",
    "sns.set(style='ticks')\n",
    "sns.relplot(data=x_prev, x='northness', y='y_pred', hue_order=Region_list, aspect=1.61)\n",
    "plt.xlabel('Northness')\n",
    "plt.ylabel('SWE Predicted (in)')\n",
    "plt.title(\"Predicted SWE by Northness\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Next [Chapter](./workflow.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c446eef832ec964573dc49f36fd16bdbed40cbfbefbf557bc2dc78d9e7968689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
